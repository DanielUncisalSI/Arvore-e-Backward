{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "#Pré-Processamento de dados\n",
    "import pandas as pd\n",
    "dados = pd.read_csv('iris.csv')\n",
    "print(dados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pegando os dados unicos\n",
    "dados['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substituindo os valores texto do rotulo por numero\n",
    "dados = dados.replace({'species':{'setosa':1.1}})\n",
    "dados = dados.replace({'species':{'versicolor':2.2}})\n",
    "dados = dados.replace({'species':{'virginica':3.3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           5.1          3.5           1.4          0.2      1.1\n",
      "1           4.9          3.0           1.4          0.2      1.1\n",
      "2           4.7          3.2           1.3          0.2      1.1\n",
      "3           4.6          3.1           1.5          0.2      1.1\n",
      "4           5.0          3.6           1.4          0.2      1.1\n"
     ]
    }
   ],
   "source": [
    "print(dados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armazenamos o quadro de dados em duas matrizes numpy - X e y:\n",
    "X = dados.iloc[:, :-1].values\n",
    "y = dados.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, -1] = labelencoder.fit_transform(X[:, -1])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [-1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#C: \\ Usuários \\ Daniel \\ Anaconda3 \\ lib \\ pacotes de sites \\ sklearn \\ preprocessing \\ _encoders.py: 415: FutureWarning: O tratamento de dados inteiros será alterado na versão 0.22. Atualmente, as categorias são determinadas com base no intervalo [0, max (valores)], enquanto no futuro serão determinadas com base nos valores exclusivos.\n",
    "#Se você quiser o comportamento futuro e silenciar este aviso, poderá especificar \"categories = 'auto'\".\n",
    "#Caso você tenha usado um LabelEncoder antes deste OneHotEncoder para converter as categorias em números inteiros, agora você pode usar o OneHotEncoder diretamente.\n",
    " # warnings.warn (msg, FutureWarning)\n",
    "#C: \\ Usuários \\ Daniel \\ Anaconda3 \\ lib \\ pacotes de sites \\ sklearn \\ preprocessing \\ _encoders.py: 451: DeprecationWarning: A palavra-chave 'categorical_features' está obsoleta na versão 0.20 e será removida na 0.22. Você pode usar o ColumnTransformer.\n",
    " # \"use o ColumnTransformer.\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train[:,3:] = scaler.fit_transform(X_train[:,3:])\n",
    "X_test[:,3:] = scaler.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445672250090675\n"
     ]
    }
   ],
   "source": [
    "#comando pra exibir a pontuação\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adcionando o valor 1 fictiio para executar a eliminação pra trás, pois somos obrigado a usar o modelo linear pela biblioteca statsmodels\n",
    "import numpy as np\n",
    "X_train = np.append (arr=np.ones([X_train.shape[0],1]).astype(int), values = X_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.066\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.017\n",
      "Method:                 Least Squares   F-statistic:                              1.345\n",
      "Date:                Tue, 12 Nov 2019   Prob (F-statistic):                       0.243\n",
      "Time:                        14:28:53   Log-Likelihood:                         -272.45\n",
      "No. Observations:                 120   AIC:                                      556.9\n",
      "Df Residuals:                     114   BIC:                                      573.6\n",
      "Df Model:                           6                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0933      1.075      1.017      0.311      -1.037       3.223\n",
      "x2             1.0933      0.502      2.179      0.031       0.099       2.087\n",
      "x3             1.0933      1.075      1.017      0.311      -1.037       3.223\n",
      "x4             1.0933      1.202      0.909      0.365      -1.288       3.475\n",
      "x5             1.0933      2.404      0.455      0.650      -3.669       5.856\n",
      "x6            -0.0733      0.220     -0.334      0.739      -0.509       0.362\n",
      "==============================================================================\n",
      "Omnibus:                      208.247   Durbin-Watson:                   0.689\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               14.535\n",
      "Skew:                          -0.454   Prob(JB):                     0.000698\n",
      "Kurtosis:                       1.556   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_opt = [0,1,2,3,4,5]\n",
    "#OLS significa 'Mínimos Quadrados Ordinários', que basicamente treina um modelo Linear.\n",
    "regressor = sm.OLS(Y_train, X_train[:,X_opt]).fit()\n",
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa linha é usada pra retirar o modelo que o valor de P está acima de  0,05\n",
    "#X_opt = [0,1,2,3,4,6]\n",
    "#regressor_OLS = sm.OLS(Y_train, X_train[:,X_opt]).fit()\n",
    "#print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.6852818199388139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[:,[0,1,2,3,4,5]], y, test_size = 0.2, random_state = 0)\n",
    "scaler = StandardScaler()\n",
    "X_train[:,5:] = scaler.fit_transform(X_train[:,5:])\n",
    "X_test[:,5:] = scaler.transform(X_test[:,5:])\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print('Model score: '+str(model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
